{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y6KkEjHKpxwC"
   },
   "source": [
    "### Initialize the spark environment and load the helper functions we have provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jva8hK90pxwF"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "rootpath = '/class/'\n",
    "datapath = f'{rootpath}datasets/'\n",
    "sys.path.append(rootpath)\n",
    "from pyspark_helpers import *\n",
    "sc, spark, conf = initspark()\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib as mp\n",
    "import numpy\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DbzStKdFpxwM"
   },
   "source": [
    "### Read in a simple dataset of latitudes and longitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zM_IDpZzpxwN"
   },
   "outputs": [],
   "source": [
    "filename = 'superchargers.csv'\n",
    "df = spark.read.csv(f'{datapath}{filename}', header = True, inferSchema = True)\n",
    "display(df)\n",
    "\n",
    "# Save a pointer to the raw data\n",
    "dfRawFile = df\n",
    "df.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3d12RxW8pxwR"
   },
   "source": [
    "### Visualize this dataset using pandas. Normally you don't do this in Spark but it is helpful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jf3-joDrpxwS"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "p = df.toPandas()\n",
    "print(p)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(p.loc[:,'lng'],p.loc[:,'lat'],'o')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YNtS0k3bpxwV"
   },
   "source": [
    "### Turn the features into a big vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "juAe-hNYpxwW"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "vecAssembler = VectorAssembler(inputCols=[\"lat\", \"lng\"], outputCol=\"features\")\n",
    "dfML = vecAssembler.transform(df)\n",
    "display(dfML)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YiQS7aWcpxwf"
   },
   "source": [
    "### Display the cluster results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "CLUSTERS = 2\n",
    "kmeans = KMeans().setK(CLUSTERS).setSeed(1)\n",
    "kmeans = KMeans(k = CLUSTERS, seed = 1)\n",
    "model = kmeans.fit(dfML)\n",
    "predictions = model.transform(dfML)\n",
    "centroids = model.clusterCenters()\n",
    "print(centroids)\n",
    "display(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the cluster results graphically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M7PxeQFNpxwh"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "print(centroids)\n",
    "for i in range(CLUSTERS):    \n",
    "    p = predictions.select('lng', 'lat').where(f'prediction = {i}').toPandas()\n",
    "    plt.plot(p.loc[:,'lng'],p.loc[:,'lat'],'o')\n",
    "    plt.plot(centroids[i][1], \n",
    "           centroids[i][0],'kx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0KDNJ3GMpxwb"
   },
   "source": [
    "### Load the KMeans class and train the model. Evaluate how good it performs for several different cluster counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oqbL9hrJpxwc"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "def evaluateCluster(model, df):\n",
    "    wssse = model.computeCost(dfML.select('features'))\n",
    "    print(\"Within Set Sum of Squared Errors = \" + str(wssse))\n",
    "\n",
    "    evaluator = ClusteringEvaluator()\n",
    "\n",
    "    predictions = model.transform(df)\n",
    "    silhouette = evaluator.evaluate(predictions)\n",
    "    print(\"Silhouette with squared euclidean distance = \" + str(silhouette))\n",
    "\n",
    "    # Shows the result.\n",
    "    centers = model.clusterCenters()\n",
    "    print(\"Cluster Centers: \")\n",
    "    for center in centers:\n",
    "        print(center)\n",
    "\n",
    "for k in range(2, 5):\n",
    "    print ('Number of clusters', k)\n",
    "    kmeans = KMeans().setK(k).setSeed(1)\n",
    "    model = kmeans.fit(dfML.select('features'))\n",
    "    evaluateCluster(model, dfML.select('features'))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yhLUXEbspxwk"
   },
   "source": [
    "### Use and elbow chart to help visualize what is the optimal number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pr1gAeuKpxwl"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def plot_elbow(df, cluster_cnt = 7):\n",
    "    import numpy as np\n",
    "    CLUSTERS = range(2, cluster_cnt)\n",
    "    scores = [KMeans().setK(c).setSeed(1).fit(df).computeCost(df)\n",
    "              for c in CLUSTERS]\n",
    "    print(scores)\n",
    "    plt.plot(CLUSTERS, scores)\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Elbow Curve')\n",
    "    plt.xticks(np.arange(2, cluster_cnt))\n",
    "\n",
    "plot_elbow(dfML.select('features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Ch04_ClusterAnalysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
