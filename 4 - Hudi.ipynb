{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-JdIfR70Jxu2"
   },
   "source": [
    "### Set up the Spark environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qwiklabs-gcp-02-39d418f1eb5a\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "result = subprocess.run([\"gcloud\", \"config\", \"get-value\", \"project\"], stdout=subprocess.PIPE)\n",
    "PROJECT_ID = result.stdout.decode(\"utf-8\").strip()\n",
    "\n",
    "# Print the output\n",
    "print(PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://qwiklabs-gcp-02-39d418f1eb5a-data/datasets gs://qwiklabs-gcp-02-39d418f1eb5a-output\n"
     ]
    }
   ],
   "source": [
    "SOURCE_PATH = f'gs://{PROJECT_ID}-data/datasets'\n",
    "DEST_PATH = f'gs://{PROJECT_ID}-output'\n",
    "print(SOURCE_PATH, DEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[orderid: int, customerid: string, employeeid: int, orderdate: string, requireddate: string, shippeddate: string, shipvia: int, freight: double, shipname: string, shipaddress: string, shipcity: string, shipregion: string, shippostalcode: string, shipcountry: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "orders = spark.read.format('avro').load(f'{SOURCE_PATH}/northwind/AVRO/orders')\n",
    "orders.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_timestamp\n",
    "\n",
    "# Assuming your data has a column named 'order_date' that can be used for timestamps\n",
    "orders = orders.withColumn('ts', current_timestamp().alias('ts'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+----------+------------+-----------+-------+-------+--------------------+--------------------+--------------+----------+--------------+-----------+--------------------+\n",
      "|orderid|customerid|employeeid| orderdate|requireddate|shippeddate|shipvia|freight|            shipname|         shipaddress|      shipcity|shipregion|shippostalcode|shipcountry|                  ts|\n",
      "+-------+----------+----------+----------+------------+-----------+-------+-------+--------------------+--------------------+--------------+----------+--------------+-----------+--------------------+\n",
      "|  10248|     VINET|         5|1996-07-04|  1996-08-01| 1996-07-16|      3|  32.38|Vins et alcools C...|  59 rue de l'Abbaye|         Reims|      NULL|         51100|     France|2025-01-22 04:13:...|\n",
      "|  10249|     TOMSP|         6|1996-07-05|  1996-08-16| 1996-07-10|      1|  11.61|  Toms Spezialitäten|       Luisenstr. 48|       Münster|      NULL|         44087|    Germany|2025-01-22 04:13:...|\n",
      "|  10250|     HANAR|         4|1996-07-08|  1996-08-05| 1996-07-12|      2|  65.83|       Hanari Carnes|     Rua do Paço, 67|Rio de Janeiro|        RJ|     05454-876|     Brazil|2025-01-22 04:13:...|\n",
      "|  10251|     VICTE|         3|1996-07-08|  1996-08-05| 1996-07-15|      1|  41.34|Victuailles en stock|  2, rue du Commerce|          Lyon|      NULL|         69004|     France|2025-01-22 04:13:...|\n",
      "|  10252|     SUPRD|         4|1996-07-09|  1996-08-06| 1996-07-11|      2|   51.3|    Suprêmes délices|Boulevard Tirou, 255|     Charleroi|      NULL|        B-6000|    Belgium|2025-01-22 04:13:...|\n",
      "|  10253|     HANAR|         3|1996-07-10|  1996-07-24| 1996-07-16|      2|  58.17|       Hanari Carnes|     Rua do Paço, 67|Rio de Janeiro|        RJ|     05454-876|     Brazil|2025-01-22 04:13:...|\n",
      "|  10254|     CHOPS|         5|1996-07-11|  1996-08-08| 1996-07-23|      2|  22.98|   Chop-suey Chinese|        Hauptstr. 31|          Bern|      NULL|          3012|Switzerland|2025-01-22 04:13:...|\n",
      "|  10255|     RICSU|         9|1996-07-12|  1996-08-09| 1996-07-15|      3| 148.33|  Richter Supermarkt|         Starenweg 5|        Genève|      NULL|          1204|Switzerland|2025-01-22 04:13:...|\n",
      "|  10256|     WELLI|         3|1996-07-15|  1996-08-12| 1996-07-17|      2|  13.97|Wellington Import...|  Rua do Mercado, 12|       Resende|        SP|     08737-363|     Brazil|2025-01-22 04:13:...|\n",
      "|  10257|     HILAA|         4|1996-07-16|  1996-08-13| 1996-07-22|      3|  81.91|    HILARION-Abastos|Carrera 22 con Av...| San Cristóbal|   Táchira|          5022|  Venezuela|2025-01-22 04:13:...|\n",
      "|  10258|     ERNSH|         1|1996-07-17|  1996-08-14| 1996-07-23|      1| 140.51|        Ernst Handel|        Kirchgasse 6|          Graz|      NULL|          8010|    Austria|2025-01-22 04:13:...|\n",
      "|  10259|     CENTC|         4|1996-07-18|  1996-08-15| 1996-07-25|      3|   3.25|Centro comercial ...|Sierras de Granad...|   México D.F.|      NULL|         05022|     Mexico|2025-01-22 04:13:...|\n",
      "|  10260|     OTTIK|         4|1996-07-19|  1996-08-16| 1996-07-29|      1|  55.09|  Ottilies Käseladen|  Mehrheimerstr. 369|          Köln|      NULL|         50739|    Germany|2025-01-22 04:13:...|\n",
      "|  10261|     QUEDE|         4|1996-07-19|  1996-08-16| 1996-07-30|      2|   3.05|         Que Delícia|Rua da Panificado...|Rio de Janeiro|        RJ|     02389-673|     Brazil|2025-01-22 04:13:...|\n",
      "|  10262|     RATTC|         8|1996-07-22|  1996-08-19| 1996-07-25|      3|  48.29|Rattlesnake Canyo...|     2817 Milton Dr.|   Albuquerque|        NM|         87110|        USA|2025-01-22 04:13:...|\n",
      "|  10263|     ERNSH|         9|1996-07-23|  1996-08-20| 1996-07-31|      3| 146.06|        Ernst Handel|        Kirchgasse 6|          Graz|      NULL|          8010|    Austria|2025-01-22 04:13:...|\n",
      "|  10264|     FOLKO|         6|1996-07-24|  1996-08-21| 1996-08-23|      3|   3.67|      Folk och fä HB|        Åkergatan 24|        Bräcke|      NULL|      S-844 67|     Sweden|2025-01-22 04:13:...|\n",
      "|  10265|     BLONP|         2|1996-07-25|  1996-08-22| 1996-08-12|      1|  55.28|Blondel père et fils|    24, place Kléber|    Strasbourg|      NULL|         67000|     France|2025-01-22 04:13:...|\n",
      "|  10266|     WARTH|         3|1996-07-26|  1996-09-06| 1996-07-31|      3|  25.73|      Wartian Herkku|         Torikatu 38|          Oulu|      NULL|         90110|    Finland|2025-01-22 04:13:...|\n",
      "|  10267|     FRANK|         4|1996-07-29|  1996-08-26| 1996-08-06|      1| 208.58|      Frankenversand|   Berliner Platz 43|       München|      NULL|         80805|    Germany|2025-01-22 04:13:...|\n",
      "+-------+----------+----------+----------+------------+-----------+-------+-------+--------------------+--------------------+--------------+----------+--------------+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2AG_7asYgUub"
   },
   "source": [
    "## Spark DataFrames can be saved to a Hive table using either the saveAsTable method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pe14VoNmgUuM",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/22 04:13:24 WARN HoodieSparkSqlWriterInternal: hoodie table at gs://qwiklabs-gcp-02-39d418f1eb5a-output/hudi/orders already exists. Deleting existing data & overwriting with new data.\n",
      "25/01/22 04:13:49 WARN HoodieSparkSqlWriterInternal: Closing write client       \n"
     ]
    }
   ],
   "source": [
    "# Hudi configurations\n",
    "hudi_table_path = f\"{DEST_PATH}/hudi/orders\"\n",
    "hudi_options = {\n",
    "    'hoodie.table.name': 'orders'\n",
    "    ,'hoodie.datasource.write.recordkey.field': 'orderid' # Primary key\n",
    "    ,'hoodie.datasource.write.partitionpath.field': ''\n",
    "    ,'hoodie.datasource.write.table.type': 'COPY_ON_WRITE'\n",
    "    ,'hoodie.datasource.write.operation': 'upsert'  # Use 'insert' for initial load\n",
    "    # ,'hoodie.deltastreamer.schemaprovider.source.schema': orders.schema.json() # Important for schema evolution with deltastreamer\n",
    "}\n",
    "\n",
    "# Write the DataFrame to Hudi\n",
    "orders.write.format(\"hudi\").options(**hudi_options).mode(\"overwrite\").save(hudi_table_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext sparksql_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">namespace</td><td style=\"font-weight: bold\">tableName</td><td style=\"font-weight: bold\">isTemporary</td></tr><tr><td>default</td><td>orders</td><td>False</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "show tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/22 04:46:38 WARN TableSchemaResolver: Could not find any data file written for commit, so could not get schema for table gs://gcs-bucket-dataproc-metastore-5bd62580-6667-45d7-a4b8-a53880bd1/hive-warehouse/orders\n",
      "25/01/22 04:46:38 WARN HoodieSparkSqlWriterInternal: hoodie table at gs://gcs-bucket-dataproc-metastore-5bd62580-6667-45d7-a4b8-a53880bd1/hive-warehouse/orders already exists. Deleting existing data & overwriting with new data.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Hudi configurations\n",
    "hudi_table_name = 'orders'\n",
    "hudi_table_path = f\"{DEST_PATH}/hudi/orders\"\n",
    "hudi_options = {\n",
    "    'hoodie.table.name': 'orders'\n",
    "    ,'hoodie.datasource.write.recordkey.field': 'orderid' # Primary key\n",
    "    ,'hoodie.datasource.write.partitionpath.field': ''\n",
    "    ,'hoodie.datasource.write.table.type': 'COPY_ON_WRITE'\n",
    "    ,'hoodie.datasource.write.operation': 'upsert'  # Use 'insert' for initial load\n",
    "    # ,'hoodie.deltastreamer.schemaprovider.source.schema': orders.schema.json() # Important for schema evolution with deltastreamer\n",
    "}\n",
    "\n",
    "# Write the DataFrame to HudiTable\n",
    "orders.write.format(\"hudi\").options(**hudi_options).mode(\"overwrite\").saveAsTable(hudi_table_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">_hoodie_commit_time</td><td style=\"font-weight: bold\">_hoodie_commit_seqno</td><td style=\"font-weight: bold\">_hoodie_record_key</td><td style=\"font-weight: bold\">_hoodie_partition_path</td><td style=\"font-weight: bold\">_hoodie_file_name</td><td style=\"font-weight: bold\">orderid</td><td style=\"font-weight: bold\">customerid</td><td style=\"font-weight: bold\">employeeid</td><td style=\"font-weight: bold\">orderdate</td><td style=\"font-weight: bold\">requireddate</td><td style=\"font-weight: bold\">shippeddate</td><td style=\"font-weight: bold\">shipvia</td><td style=\"font-weight: bold\">freight</td><td style=\"font-weight: bold\">shipname</td><td style=\"font-weight: bold\">shipaddress</td><td style=\"font-weight: bold\">shipcity</td><td style=\"font-weight: bold\">shipregion</td><td style=\"font-weight: bold\">shippostalcode</td><td style=\"font-weight: bold\">shipcountry</td><td style=\"font-weight: bold\">ts</td></tr><tr><td>20250122044640228</td><td>20250122044640228_0_2491</td><td>10248</td><td></td><td>bdf3465d-dbc2-489a-bb93-31c2b70cd628-0_0-288-1082_20250122044640228.parquet</td><td>10248</td><td>VINET</td><td>5</td><td>1996-07-04</td><td>1996-08-01</td><td>1996-07-16</td><td>3</td><td>32.38</td><td>Vins et alcools Chevalier</td><td>59 rue de l&#x27;Abbaye</td><td>Reims</td><td>null</td><td>51100</td><td>France</td><td>2025-01-22 04:46:48.526051</td></tr><tr><td>20250122044640228</td><td>20250122044640228_0_2492</td><td>10249</td><td></td><td>bdf3465d-dbc2-489a-bb93-31c2b70cd628-0_0-288-1082_20250122044640228.parquet</td><td>10249</td><td>TOMSP</td><td>6</td><td>1996-07-05</td><td>1996-08-16</td><td>1996-07-10</td><td>1</td><td>11.61</td><td>Toms Spezialitäten</td><td>Luisenstr. 48</td><td>Münster</td><td>null</td><td>44087</td><td>Germany</td><td>2025-01-22 04:46:48.526051</td></tr><tr><td>20250122044640228</td><td>20250122044640228_0_2493</td><td>10250</td><td></td><td>bdf3465d-dbc2-489a-bb93-31c2b70cd628-0_0-288-1082_20250122044640228.parquet</td><td>10250</td><td>HANAR</td><td>4</td><td>1996-07-08</td><td>1996-08-05</td><td>1996-07-12</td><td>2</td><td>65.83</td><td>Hanari Carnes</td><td>Rua do Paço, 67</td><td>Rio de Janeiro</td><td>RJ</td><td>05454-876</td><td>Brazil</td><td>2025-01-22 04:46:48.526051</td></tr><tr><td>20250122044640228</td><td>20250122044640228_0_2494</td><td>10251</td><td></td><td>bdf3465d-dbc2-489a-bb93-31c2b70cd628-0_0-288-1082_20250122044640228.parquet</td><td>10251</td><td>VICTE</td><td>3</td><td>1996-07-08</td><td>1996-08-05</td><td>1996-07-15</td><td>1</td><td>41.34</td><td>Victuailles en stock</td><td>2, rue du Commerce</td><td>Lyon</td><td>null</td><td>69004</td><td>France</td><td>2025-01-22 04:46:48.526051</td></tr><tr><td>20250122044640228</td><td>20250122044640228_0_2495</td><td>10252</td><td></td><td>bdf3465d-dbc2-489a-bb93-31c2b70cd628-0_0-288-1082_20250122044640228.parquet</td><td>10252</td><td>SUPRD</td><td>4</td><td>1996-07-09</td><td>1996-08-06</td><td>1996-07-11</td><td>2</td><td>51.3</td><td>Suprêmes délices</td><td>Boulevard Tirou, 255</td><td>Charleroi</td><td>null</td><td>B-6000</td><td>Belgium</td><td>2025-01-22 04:46:48.526051</td></tr><tr><td>20250122044640228</td><td>20250122044640228_0_2496</td><td>10253</td><td></td><td>bdf3465d-dbc2-489a-bb93-31c2b70cd628-0_0-288-1082_20250122044640228.parquet</td><td>10253</td><td>HANAR</td><td>3</td><td>1996-07-10</td><td>1996-07-24</td><td>1996-07-16</td><td>2</td><td>58.17</td><td>Hanari Carnes</td><td>Rua do Paço, 67</td><td>Rio de Janeiro</td><td>RJ</td><td>05454-876</td><td>Brazil</td><td>2025-01-22 04:46:48.526051</td></tr><tr><td>20250122044640228</td><td>20250122044640228_0_2497</td><td>10254</td><td></td><td>bdf3465d-dbc2-489a-bb93-31c2b70cd628-0_0-288-1082_20250122044640228.parquet</td><td>10254</td><td>CHOPS</td><td>5</td><td>1996-07-11</td><td>1996-08-08</td><td>1996-07-23</td><td>2</td><td>22.98</td><td>Chop-suey Chinese</td><td>Hauptstr. 31</td><td>Bern</td><td>null</td><td>3012</td><td>Switzerland</td><td>2025-01-22 04:46:48.526051</td></tr><tr><td>20250122044640228</td><td>20250122044640228_0_2498</td><td>10255</td><td></td><td>bdf3465d-dbc2-489a-bb93-31c2b70cd628-0_0-288-1082_20250122044640228.parquet</td><td>10255</td><td>RICSU</td><td>9</td><td>1996-07-12</td><td>1996-08-09</td><td>1996-07-15</td><td>3</td><td>148.33</td><td>Richter Supermarkt</td><td>Starenweg 5</td><td>Genève</td><td>null</td><td>1204</td><td>Switzerland</td><td>2025-01-22 04:46:48.526051</td></tr><tr><td>20250122044640228</td><td>20250122044640228_0_2499</td><td>10256</td><td></td><td>bdf3465d-dbc2-489a-bb93-31c2b70cd628-0_0-288-1082_20250122044640228.parquet</td><td>10256</td><td>WELLI</td><td>3</td><td>1996-07-15</td><td>1996-08-12</td><td>1996-07-17</td><td>2</td><td>13.97</td><td>Wellington Importadora</td><td>Rua do Mercado, 12</td><td>Resende</td><td>SP</td><td>08737-363</td><td>Brazil</td><td>2025-01-22 04:46:48.526051</td></tr><tr><td>20250122044640228</td><td>20250122044640228_0_2500</td><td>10257</td><td></td><td>bdf3465d-dbc2-489a-bb93-31c2b70cd628-0_0-288-1082_20250122044640228.parquet</td><td>10257</td><td>HILAA</td><td>4</td><td>1996-07-16</td><td>1996-08-13</td><td>1996-07-22</td><td>3</td><td>81.91</td><td>HILARION-Abastos</td><td>Carrera 22 con Ave. Carlos Soublette #8-35</td><td>San Cristóbal</td><td>Táchira</td><td>5022</td><td>Venezuela</td><td>2025-01-22 04:46:48.526051</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "select * from orders limit 10;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/22 04:21:39 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "25/01/22 04:22:02 WARN HoodieSparkSqlWriterInternal: Closing write client       \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "update orders set shipcountry='Spain' where orderid=10248;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">_hoodie_commit_time</td><td style=\"font-weight: bold\">_hoodie_commit_seqno</td><td style=\"font-weight: bold\">_hoodie_record_key</td><td style=\"font-weight: bold\">_hoodie_partition_path</td><td style=\"font-weight: bold\">_hoodie_file_name</td><td style=\"font-weight: bold\">orderid</td><td style=\"font-weight: bold\">customerid</td><td style=\"font-weight: bold\">employeeid</td><td style=\"font-weight: bold\">orderdate</td><td style=\"font-weight: bold\">requireddate</td><td style=\"font-weight: bold\">shippeddate</td><td style=\"font-weight: bold\">shipvia</td><td style=\"font-weight: bold\">freight</td><td style=\"font-weight: bold\">shipname</td><td style=\"font-weight: bold\">shipaddress</td><td style=\"font-weight: bold\">shipcity</td><td style=\"font-weight: bold\">shipregion</td><td style=\"font-weight: bold\">shippostalcode</td><td style=\"font-weight: bold\">shipcountry</td><td style=\"font-weight: bold\">ts</td></tr><tr><td>20250122042139615</td><td>20250122042139615_0_0</td><td>10248</td><td></td><td>0ef2c041-9652-46a8-8b55-2331f8a691ae-0_0-128-320_20250122042139615.parquet</td><td>10248</td><td>VINET</td><td>5</td><td>1996-07-04</td><td>1996-08-01</td><td>1996-07-16</td><td>3</td><td>32.38</td><td>Vins et alcools Chevalier</td><td>59 rue de l&#x27;Abbaye</td><td>Reims</td><td>null</td><td>51100</td><td>Spain</td><td>2025-01-22 04:18:57.359962</td></tr><tr><td>20250122041848647</td><td>20250122041848647_0_832</td><td>10249</td><td></td><td>0ef2c041-9652-46a8-8b55-2331f8a691ae-0_0-128-320_20250122042139615.parquet</td><td>10249</td><td>TOMSP</td><td>6</td><td>1996-07-05</td><td>1996-08-16</td><td>1996-07-10</td><td>1</td><td>11.61</td><td>Toms Spezialitäten</td><td>Luisenstr. 48</td><td>Münster</td><td>null</td><td>44087</td><td>Germany</td><td>2025-01-22 04:18:57.359962</td></tr><tr><td>20250122041848647</td><td>20250122041848647_0_833</td><td>10250</td><td></td><td>0ef2c041-9652-46a8-8b55-2331f8a691ae-0_0-128-320_20250122042139615.parquet</td><td>10250</td><td>HANAR</td><td>4</td><td>1996-07-08</td><td>1996-08-05</td><td>1996-07-12</td><td>2</td><td>65.83</td><td>Hanari Carnes</td><td>Rua do Paço, 67</td><td>Rio de Janeiro</td><td>RJ</td><td>05454-876</td><td>Brazil</td><td>2025-01-22 04:18:57.359962</td></tr><tr><td>20250122041848647</td><td>20250122041848647_0_834</td><td>10251</td><td></td><td>0ef2c041-9652-46a8-8b55-2331f8a691ae-0_0-128-320_20250122042139615.parquet</td><td>10251</td><td>VICTE</td><td>3</td><td>1996-07-08</td><td>1996-08-05</td><td>1996-07-15</td><td>1</td><td>41.34</td><td>Victuailles en stock</td><td>2, rue du Commerce</td><td>Lyon</td><td>null</td><td>69004</td><td>France</td><td>2025-01-22 04:18:57.359962</td></tr><tr><td>20250122041848647</td><td>20250122041848647_0_835</td><td>10252</td><td></td><td>0ef2c041-9652-46a8-8b55-2331f8a691ae-0_0-128-320_20250122042139615.parquet</td><td>10252</td><td>SUPRD</td><td>4</td><td>1996-07-09</td><td>1996-08-06</td><td>1996-07-11</td><td>2</td><td>51.3</td><td>Suprêmes délices</td><td>Boulevard Tirou, 255</td><td>Charleroi</td><td>null</td><td>B-6000</td><td>Belgium</td><td>2025-01-22 04:18:57.359962</td></tr><tr><td>20250122041848647</td><td>20250122041848647_0_836</td><td>10253</td><td></td><td>0ef2c041-9652-46a8-8b55-2331f8a691ae-0_0-128-320_20250122042139615.parquet</td><td>10253</td><td>HANAR</td><td>3</td><td>1996-07-10</td><td>1996-07-24</td><td>1996-07-16</td><td>2</td><td>58.17</td><td>Hanari Carnes</td><td>Rua do Paço, 67</td><td>Rio de Janeiro</td><td>RJ</td><td>05454-876</td><td>Brazil</td><td>2025-01-22 04:18:57.359962</td></tr><tr><td>20250122041848647</td><td>20250122041848647_0_837</td><td>10254</td><td></td><td>0ef2c041-9652-46a8-8b55-2331f8a691ae-0_0-128-320_20250122042139615.parquet</td><td>10254</td><td>CHOPS</td><td>5</td><td>1996-07-11</td><td>1996-08-08</td><td>1996-07-23</td><td>2</td><td>22.98</td><td>Chop-suey Chinese</td><td>Hauptstr. 31</td><td>Bern</td><td>null</td><td>3012</td><td>Switzerland</td><td>2025-01-22 04:18:57.359962</td></tr><tr><td>20250122041848647</td><td>20250122041848647_0_838</td><td>10255</td><td></td><td>0ef2c041-9652-46a8-8b55-2331f8a691ae-0_0-128-320_20250122042139615.parquet</td><td>10255</td><td>RICSU</td><td>9</td><td>1996-07-12</td><td>1996-08-09</td><td>1996-07-15</td><td>3</td><td>148.33</td><td>Richter Supermarkt</td><td>Starenweg 5</td><td>Genève</td><td>null</td><td>1204</td><td>Switzerland</td><td>2025-01-22 04:18:57.359962</td></tr><tr><td>20250122041848647</td><td>20250122041848647_0_839</td><td>10256</td><td></td><td>0ef2c041-9652-46a8-8b55-2331f8a691ae-0_0-128-320_20250122042139615.parquet</td><td>10256</td><td>WELLI</td><td>3</td><td>1996-07-15</td><td>1996-08-12</td><td>1996-07-17</td><td>2</td><td>13.97</td><td>Wellington Importadora</td><td>Rua do Mercado, 12</td><td>Resende</td><td>SP</td><td>08737-363</td><td>Brazil</td><td>2025-01-22 04:18:57.359962</td></tr><tr><td>20250122041848647</td><td>20250122041848647_0_840</td><td>10257</td><td></td><td>0ef2c041-9652-46a8-8b55-2331f8a691ae-0_0-128-320_20250122042139615.parquet</td><td>10257</td><td>HILAA</td><td>4</td><td>1996-07-16</td><td>1996-08-13</td><td>1996-07-22</td><td>3</td><td>81.91</td><td>HILARION-Abastos</td><td>Carrera 22 con Ave. Carlos Soublette #8-35</td><td>San Cristóbal</td><td>Táchira</td><td>5022</td><td>Venezuela</td><td>2025-01-22 04:18:57.359962</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "select * from orders limit 10;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/22 04:35:44 WARN TableSchemaResolver: Could not find any data file written for commit, so could not get schema for table gs://gcs-bucket-dataproc-metastore-5bd62580-6667-45d7-a4b8-a53880bd1/hive-warehouse/orders2\n",
      "25/01/22 04:35:44 WARN HoodieSparkSqlWriterInternal: hoodie table at gs://gcs-bucket-dataproc-metastore-5bd62580-6667-45d7-a4b8-a53880bd1/hive-warehouse/orders2 already exists. Deleting existing data & overwriting with new data.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Hudi configurations\n",
    "hudi_table_name = 'orders2'\n",
    "hudi_options = {\n",
    "    'hoodie.table.name': 'orders'\n",
    "    ,'hoodie.datasource.write.recordkey.field': 'orderid' # Primary key\n",
    "    ,'hoodie.datasource.write.partitionpath.field': ''\n",
    "    ,'hoodie.datasource.write.table.type': 'MERGE_ON_READ'\n",
    "    ,'hoodie.datasource.write.operation': 'upsert'  # Use 'insert' for initial load\n",
    "    ,'hoodie.compact.inline': 'false'  # Disable inline compaction for MoR\n",
    "    ,'hoodie.compact.async.enable': 'true'  # Enable asynchronous compaction\n",
    "    ,'hoodie.cleaner.policy': 'KEEP_LATEST_FILE_VERSIONS'  # Data retention policy\n",
    "    ,'hoodie.cleaner.fileversions.retained': '2'  # Number of versions to keep\n",
    "    # ,'hoodie.deltastreamer.schemaprovider.source.schema': orders.schema.json() # Important for schema evolution with deltastreamer\n",
    "}\n",
    "\n",
    "# Write the DataFrame to HudiTable\n",
    "orders.write.format(\"hudi\").options(**hudi_options).mode(\"overwrite\").saveAsTable(hudi_table_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">_hoodie_commit_time</td><td style=\"font-weight: bold\">_hoodie_commit_seqno</td><td style=\"font-weight: bold\">_hoodie_record_key</td><td style=\"font-weight: bold\">_hoodie_partition_path</td><td style=\"font-weight: bold\">_hoodie_file_name</td><td style=\"font-weight: bold\">orderid</td><td style=\"font-weight: bold\">customerid</td><td style=\"font-weight: bold\">employeeid</td><td style=\"font-weight: bold\">orderdate</td><td style=\"font-weight: bold\">requireddate</td><td style=\"font-weight: bold\">shippeddate</td><td style=\"font-weight: bold\">shipvia</td><td style=\"font-weight: bold\">freight</td><td style=\"font-weight: bold\">shipname</td><td style=\"font-weight: bold\">shipaddress</td><td style=\"font-weight: bold\">shipcity</td><td style=\"font-weight: bold\">shipregion</td><td style=\"font-weight: bold\">shippostalcode</td><td style=\"font-weight: bold\">shipcountry</td><td style=\"font-weight: bold\">ts</td></tr><tr><td>20250122042813110</td><td>20250122042813110_0_0</td><td>10248</td><td></td><td>0ef2c041-9652-46a8-8b55-2331f8a691ae-0_0-213-806_20250122042813110.parquet</td><td>10248</td><td>VINET</td><td>5</td><td>1996-07-04</td><td>1996-08-01</td><td>1996-07-16</td><td>3</td><td>32.38</td><td>Vins et alcools Chevalier</td><td>59 rue de l&#x27;Abbaye</td><td>Reims</td><td>null</td><td>51100</td><td>Spain</td><td>2025-01-22 04:18:57.359962</td></tr><tr><td>20250122041848647</td><td>20250122041848647_0_832</td><td>10249</td><td></td><td>0ef2c041-9652-46a8-8b55-2331f8a691ae-0_0-213-806_20250122042813110.parquet</td><td>10249</td><td>TOMSP</td><td>6</td><td>1996-07-05</td><td>1996-08-16</td><td>1996-07-10</td><td>1</td><td>11.61</td><td>Toms Spezialitäten</td><td>Luisenstr. 48</td><td>Münster</td><td>null</td><td>44087</td><td>Germany</td><td>2025-01-22 04:18:57.359962</td></tr><tr><td>20250122041848647</td><td>20250122041848647_0_833</td><td>10250</td><td></td><td>0ef2c041-9652-46a8-8b55-2331f8a691ae-0_0-213-806_20250122042813110.parquet</td><td>10250</td><td>HANAR</td><td>4</td><td>1996-07-08</td><td>1996-08-05</td><td>1996-07-12</td><td>2</td><td>65.83</td><td>Hanari Carnes</td><td>Rua do Paço, 67</td><td>Rio de Janeiro</td><td>RJ</td><td>05454-876</td><td>Brazil</td><td>2025-01-22 04:18:57.359962</td></tr><tr><td>20250122041848647</td><td>20250122041848647_0_834</td><td>10251</td><td></td><td>0ef2c041-9652-46a8-8b55-2331f8a691ae-0_0-213-806_20250122042813110.parquet</td><td>10251</td><td>VICTE</td><td>3</td><td>1996-07-08</td><td>1996-08-05</td><td>1996-07-15</td><td>1</td><td>41.34</td><td>Victuailles en stock</td><td>2, rue du Commerce</td><td>Lyon</td><td>null</td><td>69004</td><td>France</td><td>2025-01-22 04:18:57.359962</td></tr><tr><td>20250122041848647</td><td>20250122041848647_0_835</td><td>10252</td><td></td><td>0ef2c041-9652-46a8-8b55-2331f8a691ae-0_0-213-806_20250122042813110.parquet</td><td>10252</td><td>SUPRD</td><td>4</td><td>1996-07-09</td><td>1996-08-06</td><td>1996-07-11</td><td>2</td><td>51.3</td><td>Suprêmes délices</td><td>Boulevard Tirou, 255</td><td>Charleroi</td><td>null</td><td>B-6000</td><td>Belgium</td><td>2025-01-22 04:18:57.359962</td></tr><tr><td>20250122041848647</td><td>20250122041848647_0_836</td><td>10253</td><td></td><td>0ef2c041-9652-46a8-8b55-2331f8a691ae-0_0-213-806_20250122042813110.parquet</td><td>10253</td><td>HANAR</td><td>3</td><td>1996-07-10</td><td>1996-07-24</td><td>1996-07-16</td><td>2</td><td>58.17</td><td>Hanari Carnes</td><td>Rua do Paço, 67</td><td>Rio de Janeiro</td><td>RJ</td><td>05454-876</td><td>Brazil</td><td>2025-01-22 04:18:57.359962</td></tr><tr><td>20250122041848647</td><td>20250122041848647_0_837</td><td>10254</td><td></td><td>0ef2c041-9652-46a8-8b55-2331f8a691ae-0_0-213-806_20250122042813110.parquet</td><td>10254</td><td>CHOPS</td><td>5</td><td>1996-07-11</td><td>1996-08-08</td><td>1996-07-23</td><td>2</td><td>22.98</td><td>Chop-suey Chinese</td><td>Hauptstr. 31</td><td>Bern</td><td>null</td><td>3012</td><td>Switzerland</td><td>2025-01-22 04:18:57.359962</td></tr><tr><td>20250122041848647</td><td>20250122041848647_0_838</td><td>10255</td><td></td><td>0ef2c041-9652-46a8-8b55-2331f8a691ae-0_0-213-806_20250122042813110.parquet</td><td>10255</td><td>RICSU</td><td>9</td><td>1996-07-12</td><td>1996-08-09</td><td>1996-07-15</td><td>3</td><td>148.33</td><td>Richter Supermarkt</td><td>Starenweg 5</td><td>Genève</td><td>null</td><td>1204</td><td>Switzerland</td><td>2025-01-22 04:18:57.359962</td></tr><tr><td>20250122041848647</td><td>20250122041848647_0_839</td><td>10256</td><td></td><td>0ef2c041-9652-46a8-8b55-2331f8a691ae-0_0-213-806_20250122042813110.parquet</td><td>10256</td><td>WELLI</td><td>3</td><td>1996-07-15</td><td>1996-08-12</td><td>1996-07-17</td><td>2</td><td>13.97</td><td>Wellington Importadora</td><td>Rua do Mercado, 12</td><td>Resende</td><td>SP</td><td>08737-363</td><td>Brazil</td><td>2025-01-22 04:18:57.359962</td></tr><tr><td>20250122041848647</td><td>20250122041848647_0_840</td><td>10257</td><td></td><td>0ef2c041-9652-46a8-8b55-2331f8a691ae-0_0-213-806_20250122042813110.parquet</td><td>10257</td><td>HILAA</td><td>4</td><td>1996-07-16</td><td>1996-08-13</td><td>1996-07-22</td><td>3</td><td>81.91</td><td>HILARION-Abastos</td><td>Carrera 22 con Ave. Carlos Soublette #8-35</td><td>San Cristóbal</td><td>Táchira</td><td>5022</td><td>Venezuela</td><td>2025-01-22 04:18:57.359962</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "select * from orders limit 10;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/22 04:52:33 WARN HoodieSparkSqlWriterInternal: Closing write client       \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "update orders set shipcountry='Spain' where orderid=10248;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">_hoodie_commit_time</td><td style=\"font-weight: bold\">_hoodie_commit_seqno</td><td style=\"font-weight: bold\">_hoodie_record_key</td><td style=\"font-weight: bold\">_hoodie_partition_path</td><td style=\"font-weight: bold\">_hoodie_file_name</td><td style=\"font-weight: bold\">orderid</td><td style=\"font-weight: bold\">customerid</td><td style=\"font-weight: bold\">employeeid</td><td style=\"font-weight: bold\">orderdate</td><td style=\"font-weight: bold\">requireddate</td><td style=\"font-weight: bold\">shippeddate</td><td style=\"font-weight: bold\">shipvia</td><td style=\"font-weight: bold\">freight</td><td style=\"font-weight: bold\">shipname</td><td style=\"font-weight: bold\">shipaddress</td><td style=\"font-weight: bold\">shipcity</td><td style=\"font-weight: bold\">shipregion</td><td style=\"font-weight: bold\">shippostalcode</td><td style=\"font-weight: bold\">shipcountry</td><td style=\"font-weight: bold\">ts</td></tr><tr><td>20250122043641024</td><td>20250122043641024_0_0</td><td>10248</td><td></td><td>0ef2c041-9652-46a8-8b55-2331f8a691ae-0_0-257-1051_20250122043641024.parquet</td><td>10248</td><td>VINET</td><td>5</td><td>1996-07-04</td><td>1996-08-01</td><td>1996-07-16</td><td>3</td><td>32.38</td><td>Vins et alcools Chevalier</td><td>59 rue de l&#x27;Abbaye</td><td>Reims</td><td>null</td><td>51100</td><td>Spain</td><td>2025-01-22 04:18:57.359962</td></tr><tr><td>20250122041848647</td><td>20250122041848647_0_832</td><td>10249</td><td></td><td>0ef2c041-9652-46a8-8b55-2331f8a691ae-0_0-257-1051_20250122043641024.parquet</td><td>10249</td><td>TOMSP</td><td>6</td><td>1996-07-05</td><td>1996-08-16</td><td>1996-07-10</td><td>1</td><td>11.61</td><td>Toms Spezialitäten</td><td>Luisenstr. 48</td><td>Münster</td><td>null</td><td>44087</td><td>Germany</td><td>2025-01-22 04:18:57.359962</td></tr><tr><td>20250122041848647</td><td>20250122041848647_0_833</td><td>10250</td><td></td><td>0ef2c041-9652-46a8-8b55-2331f8a691ae-0_0-257-1051_20250122043641024.parquet</td><td>10250</td><td>HANAR</td><td>4</td><td>1996-07-08</td><td>1996-08-05</td><td>1996-07-12</td><td>2</td><td>65.83</td><td>Hanari Carnes</td><td>Rua do Paço, 67</td><td>Rio de Janeiro</td><td>RJ</td><td>05454-876</td><td>Brazil</td><td>2025-01-22 04:18:57.359962</td></tr><tr><td>20250122041848647</td><td>20250122041848647_0_834</td><td>10251</td><td></td><td>0ef2c041-9652-46a8-8b55-2331f8a691ae-0_0-257-1051_20250122043641024.parquet</td><td>10251</td><td>VICTE</td><td>3</td><td>1996-07-08</td><td>1996-08-05</td><td>1996-07-15</td><td>1</td><td>41.34</td><td>Victuailles en stock</td><td>2, rue du Commerce</td><td>Lyon</td><td>null</td><td>69004</td><td>France</td><td>2025-01-22 04:18:57.359962</td></tr><tr><td>20250122041848647</td><td>20250122041848647_0_835</td><td>10252</td><td></td><td>0ef2c041-9652-46a8-8b55-2331f8a691ae-0_0-257-1051_20250122043641024.parquet</td><td>10252</td><td>SUPRD</td><td>4</td><td>1996-07-09</td><td>1996-08-06</td><td>1996-07-11</td><td>2</td><td>51.3</td><td>Suprêmes délices</td><td>Boulevard Tirou, 255</td><td>Charleroi</td><td>null</td><td>B-6000</td><td>Belgium</td><td>2025-01-22 04:18:57.359962</td></tr><tr><td>20250122041848647</td><td>20250122041848647_0_836</td><td>10253</td><td></td><td>0ef2c041-9652-46a8-8b55-2331f8a691ae-0_0-257-1051_20250122043641024.parquet</td><td>10253</td><td>HANAR</td><td>3</td><td>1996-07-10</td><td>1996-07-24</td><td>1996-07-16</td><td>2</td><td>58.17</td><td>Hanari Carnes</td><td>Rua do Paço, 67</td><td>Rio de Janeiro</td><td>RJ</td><td>05454-876</td><td>Brazil</td><td>2025-01-22 04:18:57.359962</td></tr><tr><td>20250122041848647</td><td>20250122041848647_0_837</td><td>10254</td><td></td><td>0ef2c041-9652-46a8-8b55-2331f8a691ae-0_0-257-1051_20250122043641024.parquet</td><td>10254</td><td>CHOPS</td><td>5</td><td>1996-07-11</td><td>1996-08-08</td><td>1996-07-23</td><td>2</td><td>22.98</td><td>Chop-suey Chinese</td><td>Hauptstr. 31</td><td>Bern</td><td>null</td><td>3012</td><td>Switzerland</td><td>2025-01-22 04:18:57.359962</td></tr><tr><td>20250122041848647</td><td>20250122041848647_0_838</td><td>10255</td><td></td><td>0ef2c041-9652-46a8-8b55-2331f8a691ae-0_0-257-1051_20250122043641024.parquet</td><td>10255</td><td>RICSU</td><td>9</td><td>1996-07-12</td><td>1996-08-09</td><td>1996-07-15</td><td>3</td><td>148.33</td><td>Richter Supermarkt</td><td>Starenweg 5</td><td>Genève</td><td>null</td><td>1204</td><td>Switzerland</td><td>2025-01-22 04:18:57.359962</td></tr><tr><td>20250122041848647</td><td>20250122041848647_0_839</td><td>10256</td><td></td><td>0ef2c041-9652-46a8-8b55-2331f8a691ae-0_0-257-1051_20250122043641024.parquet</td><td>10256</td><td>WELLI</td><td>3</td><td>1996-07-15</td><td>1996-08-12</td><td>1996-07-17</td><td>2</td><td>13.97</td><td>Wellington Importadora</td><td>Rua do Mercado, 12</td><td>Resende</td><td>SP</td><td>08737-363</td><td>Brazil</td><td>2025-01-22 04:18:57.359962</td></tr><tr><td>20250122041848647</td><td>20250122041848647_0_840</td><td>10257</td><td></td><td>0ef2c041-9652-46a8-8b55-2331f8a691ae-0_0-257-1051_20250122043641024.parquet</td><td>10257</td><td>HILAA</td><td>4</td><td>1996-07-16</td><td>1996-08-13</td><td>1996-07-22</td><td>3</td><td>81.91</td><td>HILARION-Abastos</td><td>Carrera 22 con Ave. Carlos Soublette #8-35</td><td>San Cristóbal</td><td>Táchira</td><td>5022</td><td>Venezuela</td><td>2025-01-22 04:18:57.359962</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "select * from orders limit 10;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------------------+------------------+----------------------+---------------------------------------------------------------------------+-------+----------+----------+----------+------------+-----------+-------+-------+-------------------------+------------------+--------+----------+--------------+-----------+--------------------------+\n",
      "|_hoodie_commit_time|_hoodie_commit_seqno |_hoodie_record_key|_hoodie_partition_path|_hoodie_file_name                                                          |orderid|customerid|employeeid|orderdate |requireddate|shippeddate|shipvia|freight|shipname                 |shipaddress       |shipcity|shipregion|shippostalcode|shipcountry|ts                        |\n",
      "+-------------------+---------------------+------------------+----------------------+---------------------------------------------------------------------------+-------+----------+----------+----------+------------+-----------+-------+-------+-------------------------+------------------+--------+----------+--------------+-----------+--------------------------+\n",
      "|20250122043641024  |20250122043641024_0_0|10248             |                      |0ef2c041-9652-46a8-8b55-2331f8a691ae-0_0-257-1051_20250122043641024.parquet|10248  |VINET     |5         |1996-07-04|1996-08-01  |1996-07-16 |3      |32.38  |Vins et alcools Chevalier|59 rue de l'Abbaye|Reims   |NULL      |51100         |Spain      |2025-01-22 04:18:57.359962|\n",
      "+-------------------+---------------------+------------------+----------------------+---------------------------------------------------------------------------+-------+----------+----------+----------+------------+-----------+-------+-------+-------------------------+------------------+--------+----------+--------------+-----------+--------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_hoodie_commit_time</th>\n",
       "      <th>_hoodie_commit_seqno</th>\n",
       "      <th>_hoodie_record_key</th>\n",
       "      <th>_hoodie_partition_path</th>\n",
       "      <th>_hoodie_file_name</th>\n",
       "      <th>orderid</th>\n",
       "      <th>customerid</th>\n",
       "      <th>employeeid</th>\n",
       "      <th>orderdate</th>\n",
       "      <th>requireddate</th>\n",
       "      <th>shippeddate</th>\n",
       "      <th>shipvia</th>\n",
       "      <th>freight</th>\n",
       "      <th>shipname</th>\n",
       "      <th>shipaddress</th>\n",
       "      <th>shipcity</th>\n",
       "      <th>shipregion</th>\n",
       "      <th>shippostalcode</th>\n",
       "      <th>shipcountry</th>\n",
       "      <th>ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20250122043641024</td>\n",
       "      <td>20250122043641024_0_0</td>\n",
       "      <td>10248</td>\n",
       "      <td></td>\n",
       "      <td>0ef2c041-9652-46a8-8b55-2331f8a691ae-0_0-257-1...</td>\n",
       "      <td>10248</td>\n",
       "      <td>VINET</td>\n",
       "      <td>5</td>\n",
       "      <td>1996-07-04</td>\n",
       "      <td>1996-08-01</td>\n",
       "      <td>1996-07-16</td>\n",
       "      <td>3</td>\n",
       "      <td>32.38</td>\n",
       "      <td>Vins et alcools Chevalier</td>\n",
       "      <td>59 rue de l'Abbaye</td>\n",
       "      <td>Reims</td>\n",
       "      <td>None</td>\n",
       "      <td>51100</td>\n",
       "      <td>Spain</td>\n",
       "      <td>2025-01-22 04:18:57.359962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  _hoodie_commit_time   _hoodie_commit_seqno _hoodie_record_key  \\\n",
       "0   20250122043641024  20250122043641024_0_0              10248   \n",
       "\n",
       "  _hoodie_partition_path                                  _hoodie_file_name  \\\n",
       "0                         0ef2c041-9652-46a8-8b55-2331f8a691ae-0_0-257-1...   \n",
       "\n",
       "   orderid customerid  employeeid   orderdate requireddate shippeddate  \\\n",
       "0    10248      VINET           5  1996-07-04   1996-08-01  1996-07-16   \n",
       "\n",
       "   shipvia  freight                   shipname         shipaddress shipcity  \\\n",
       "0        3    32.38  Vins et alcools Chevalier  59 rue de l'Abbaye    Reims   \n",
       "\n",
       "  shipregion shippostalcode shipcountry                         ts  \n",
       "0       None          51100       Spain 2025-01-22 04:18:57.359962  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "previous version\n",
      "Row(_hoodie_commit_time='20250122043641024', _hoodie_commit_seqno='20250122043641024_0_0', _hoodie_record_key='10248', _hoodie_partition_path='', _hoodie_file_name='0ef2c041-9652-46a8-8b55-2331f8a691ae-0_0-257-1051_20250122043641024.parquet', orderid=10248, customerid='VINET', employeeid=5, orderdate='1996-07-04', requireddate='1996-08-01', shippeddate='1996-07-16', shipvia=3, freight=32.38, shipname='Vins et alcools Chevalier', shipaddress=\"59 rue de l'Abbaye\", shipcity='Reims', shipregion=None, shippostalcode='51100', shipcountry='Spain', ts=datetime.datetime(2025, 1, 22, 4, 18, 57, 359962))\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df = spark.table(\"orders\")\n",
    "\n",
    "# Specify the record key you're interested in\n",
    "record_key_to_find = \"10248\"\n",
    "\n",
    "# Find all versions of the record\n",
    "record_versions = df.filter(col(\"_hoodie_record_key\") == record_key_to_find).orderBy(col(\"_hoodie_commit_time\").desc())\n",
    "\n",
    "# Show all versions of the record\n",
    "record_versions.show(truncate=False)\n",
    "\n",
    "# Get the second most recent version (the previous version)\n",
    "previous_version = record_versions.limit(2).tail(1)[0]\n",
    "#convert to dataframe to use display\n",
    "previous_version_df = spark.createDataFrame([previous_version], record_versions.schema)\n",
    "\n",
    "display(previous_version_df.toPandas())\n",
    "\n",
    "#or just show it\n",
    "print(\"previous version\")\n",
    "print(previous_version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">_hoodie_commit_time</td><td style=\"font-weight: bold\">_hoodie_commit_seqno</td><td style=\"font-weight: bold\">_hoodie_record_key</td><td style=\"font-weight: bold\">_hoodie_partition_path</td><td style=\"font-weight: bold\">_hoodie_file_name</td><td style=\"font-weight: bold\">orderid</td><td style=\"font-weight: bold\">customerid</td><td style=\"font-weight: bold\">employeeid</td><td style=\"font-weight: bold\">orderdate</td><td style=\"font-weight: bold\">requireddate</td><td style=\"font-weight: bold\">shippeddate</td><td style=\"font-weight: bold\">shipvia</td><td style=\"font-weight: bold\">freight</td><td style=\"font-weight: bold\">shipname</td><td style=\"font-weight: bold\">shipaddress</td><td style=\"font-weight: bold\">shipcity</td><td style=\"font-weight: bold\">shipregion</td><td style=\"font-weight: bold\">shippostalcode</td><td style=\"font-weight: bold\">shipcountry</td><td style=\"font-weight: bold\">ts</td></tr><tr><td>20250122045211776</td><td>20250122045211776_0_0</td><td>10248</td><td></td><td>bdf3465d-dbc2-489a-bb93-31c2b70cd628-0_0-307-1302_20250122045211776.parquet</td><td>10248</td><td>VINET</td><td>5</td><td>1996-07-04</td><td>1996-08-01</td><td>1996-07-16</td><td>3</td><td>32.38</td><td>Vins et alcools Chevalier</td><td>59 rue de l&#x27;Abbaye</td><td>Reims</td><td>null</td><td>51100</td><td>Spain</td><td>2025-01-22 04:46:48.526051</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "select * from orders where orderid = 10248"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">_hoodie_commit_time</td><td style=\"font-weight: bold\">_hoodie_commit_seqno</td><td style=\"font-weight: bold\">_hoodie_record_key</td><td style=\"font-weight: bold\">_hoodie_partition_path</td><td style=\"font-weight: bold\">_hoodie_file_name</td><td style=\"font-weight: bold\">orderid</td><td style=\"font-weight: bold\">customerid</td><td style=\"font-weight: bold\">employeeid</td><td style=\"font-weight: bold\">orderdate</td><td style=\"font-weight: bold\">requireddate</td><td style=\"font-weight: bold\">shippeddate</td><td style=\"font-weight: bold\">shipvia</td><td style=\"font-weight: bold\">freight</td><td style=\"font-weight: bold\">shipname</td><td style=\"font-weight: bold\">shipaddress</td><td style=\"font-weight: bold\">shipcity</td><td style=\"font-weight: bold\">shipregion</td><td style=\"font-weight: bold\">shippostalcode</td><td style=\"font-weight: bold\">shipcountry</td><td style=\"font-weight: bold\">ts</td></tr><tr><td>20250122044640228</td><td>20250122044640228_0_2491</td><td>10248</td><td></td><td>bdf3465d-dbc2-489a-bb93-31c2b70cd628-0_0-288-1082_20250122044640228.parquet</td><td>10248</td><td>VINET</td><td>5</td><td>1996-07-04</td><td>1996-08-01</td><td>1996-07-16</td><td>3</td><td>32.38</td><td>Vins et alcools Chevalier</td><td>59 rue de l&#x27;Abbaye</td><td>Reims</td><td>null</td><td>51100</td><td>France</td><td>2025-01-22 04:46:48.526051</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "select * from orders TIMESTAMP as of '2025-01-22 04:46:40' where orderid = 10248"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S2mr3DIKgUuL"
   },
   "source": [
    "## You can query an existing Hudi table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7uNzTBr_gUuR"
   },
   "source": [
    "## Read in a file to a Spark DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9O2HurUbgUuS",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------------+\n",
      "|CategoryID|  CategoryName|         Description|\n",
      "+----------+--------------+--------------------+\n",
      "|         1|     Beverages|Soft drinks coffe...|\n",
      "|         2|    Condiments|Sweet and savory ...|\n",
      "|         3|   Confections|Desserts candies ...|\n",
      "|         4|Dairy Products|             Cheeses|\n",
      "|         5|Grains/Cereals|Breads crackers p...|\n",
      "|         6|  Meat/Poultry|      Prepared meats|\n",
      "|         7|       Produce|Dried fruit and b...|\n",
      "|         8|       Seafood|    Seaweed and fish|\n",
      "+----------+--------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categories = spark.read.csv(f'{SOURCE_PATH}/northwind/CSVHeaders/categories', header=True)\n",
    "categories.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "55rxI7rhgUuW"
   },
   "source": [
    "## Use createOrReplaceTempView to create a virtual table in the Hive catalog and then it can be queried using SQL as if it were a hive table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B1QjuhcTgUuX",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------------------+\n",
      "|CategoryID|CategoryName|         Description|\n",
      "+----------+------------+--------------------+\n",
      "|         1|   Beverages|Soft drinks coffe...|\n",
      "+----------+------------+--------------------+\n",
      "\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "categories.createOrReplaceTempView('categories')\n",
    "t1 =spark.sql('select * from categories where categoryid = 1')\n",
    "t1.show()\n",
    "print(t1.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The create table as syntax also works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c_t3CY5kgUud"
   },
   "outputs": [],
   "source": [
    "spark.sql('create table categories2 as select * from categories')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8YgAW8SdgUuh"
   },
   "source": [
    "## Queries use standard HQL to mix Hive tables and virtual tables. Both are read into a Spark DataFrame and the processing happens at the Spark level, not at the Hive level. HQL is just used to parse the logic into the corresponding Spark methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B5TTOFx_gUui",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+---------+--------------------+\n",
      "|CategoryID|  categoryname|productid|         productname|\n",
      "+----------+--------------+---------+--------------------+\n",
      "|         1|     Beverages|        1|                Chai|\n",
      "|         2|    Condiments|        2|               Chang|\n",
      "|         3|   Confections|        3|       Aniseed Syrup|\n",
      "|         4|Dairy Products|        4|Chef Anton's Caju...|\n",
      "|         5|Grains/Cereals|        5|Chef Anton's Gumb...|\n",
      "|         6|  Meat/Poultry|        6|Grandma's Boysenb...|\n",
      "|         7|       Produce|        7|Uncle Bob's Organ...|\n",
      "|         8|       Seafood|        8|Northwoods Cranbe...|\n",
      "+----------+--------------+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "SELECT c.categoryid, c.categoryname, p.productid, p.productname\n",
    "from categories as c\n",
    "join products as p on c.categoryid = p.categoryid\n",
    "order by c.categoryid, p.productid\n",
    "\"\"\"\n",
    "df = spark.sql(sql)\n",
    "# df.show(10)\n",
    "\n",
    "df2 = categories.join(prod, categories.CategoryID == prod.productid) \\\n",
    "                .select(categories.CategoryID, 'categoryname', 'productid', 'productname') \\\n",
    "                .orderBy(categories.CategoryID, 'productid')\n",
    "\n",
    "df2.show(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gZfSSRw3gUvF"
   },
   "source": [
    "## Creating the regions2 DataFrame does not execute anything yet, but by making the DataFrame into a Temp View then running a Spark SQL query, it tells Spark to read the SQL data into a DataFrame and then use the cluster to do the processing, not the SQL source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NqdUrSUTgUvG"
   },
   "outputs": [],
   "source": [
    "regions2.createOrReplaceTempView('regions2')\n",
    "spark.sql('select * from regions2 where regionid < 3').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jp8yIQMBoI0I"
   },
   "outputs": [],
   "source": [
    "spark.read.table('regions2').where('regionid < 3').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xt_OCqzCgUvK"
   },
   "source": [
    "## Alternate ways to code a query using SQL and methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZTph5vnOgUvL"
   },
   "outputs": [],
   "source": [
    "print(spark.sql('select count(*) from regions').collect())\n",
    "spark.sql('select * from regions').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZQf2QOj2gUvQ"
   },
   "source": [
    "## Using SQL you can use familiar syntax instead of withColumn or withColumnRenamed methods.\n",
    "Note the expr function needs to be imported when you want to use a stringified SQL function using dot syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1p18BQ_pgUvR"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "t1 = spark.sql('select TerritoryID as TerrID, UPPER(TerritoryName) as TerritoryName, RegionID from territories')\n",
    "t1.show(5)\n",
    "\n",
    "from pyspark.sql.functions import expr\n",
    "territories.withColumn('TerritoryName', expr('UPPER(TerritoryName)')).withColumnRenamed('TerritoryID', 'TerrID').show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nsi73PpHoI0f"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# This won't work though if you want to use python functions, you need to go another step\n",
    "# territories.withColumn('TerritoryName', territories.TerritoryName.upper()).show()\n",
    "\n",
    "# You need to make the python function callable by spark by wrapping it in the udf function\n",
    "# which tells spark what datatype it returns\n",
    "territories.withColumn('TerritoryName', udf(str.upper, StringType())(territories.TerritoryName)).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E1_Baqf6gUvV"
   },
   "source": [
    "## If you want to use a function that is not a standard Python or SQL function, you can always create one in Python and make it callable from Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3DZ-p4MmoI0i"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "def inventoryvalue(quantity, price):\n",
    "    return quantity * price\n",
    "\n",
    "# Turn the Python function into a Spark callable function\n",
    "invvalue = udf(inventoryvalue, FloatType())\n",
    "p = products\n",
    "p2 = p.withColumn('value', invvalue(p.unitsinstock, p.unitprice))\n",
    "display(p2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ANiYGYGoI0m"
   },
   "source": [
    "## Python decorators are an even better option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nQUKWKd3oI0n"
   },
   "outputs": [],
   "source": [
    "@udf(FloatType())\n",
    "def inventoryvalue(quantity, price):\n",
    "    return quantity * price\n",
    "\n",
    "p2 = p.withColumn('value', inventoryvalue(p.unitsinstock, p.unitprice))\n",
    "display(p2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "83gxIGtQoI0p"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "def inventoryvalue(quantity, price):\n",
    "    return quantity * price\n",
    "\n",
    "# Or dynamically wrap it, but it's harder to read\n",
    "p2 = p.withColumn('value', udf(inventoryvalue, FloatType())(p.unitsinstock, p.unitprice))\n",
    "display(p2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "scBBkmrFgUvd"
   },
   "source": [
    "## To make it easier though, you could make the Python function into a udf that SQL can understand similar to how you can make a DataFrame seem like a virtual table with createOrReplaceTempView."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A64igGvvgUvh"
   },
   "outputs": [],
   "source": [
    "def reverseString(x):\n",
    "    return x[::-1]\n",
    "\n",
    "spark.udf.register('reverse', reverseString, StringType())\n",
    "\n",
    "spark.sql('select *, reverse(TerritoryName) as Reversed from Territories').orderBy('Reversed').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "11AafIOegUvl"
   },
   "source": [
    "## HQL has collect_set and collect_list functions to aggregate items into a list instead of summing them up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cRm3IkEpgUvl",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import collect_list\n",
    "territories.groupBy(territories.RegionID).agg(collect_list(territories.TerritoryName)).show()\n",
    "\n",
    "tr1 = spark.sql(\"SELECT RegionID, collect_list(TerritoryName) AS TerritoryList FROM Territories GROUP BY RegionID\")\n",
    "tr1.show()\n",
    "tr1.printSchema()\n",
    "print(tr1.take(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l-onOtyzgUvo"
   },
   "source": [
    "## Instead of a simple datatype, you could also collect complex structured objects using the HQL NAMED_STRUCT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tolziu_tgUvp"
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT r.RegionID, r.RegionName\n",
    ", COLLECT_SET(NAMED_STRUCT(\"TerritoryID\", TerritoryID, \"TerritoryName\", TerritoryName)) AS TerritoryList\n",
    "FROM Regions AS r\n",
    "JOIN Territories AS t ON r.RegionID = t.RegionID\n",
    "GROUP BY r.RegionID, r.RegionName\n",
    "ORDER BY r.RegionID\n",
    "\"\"\"\n",
    "\n",
    "tr2 = spark.sql(sql)\n",
    "tr2.printSchema()\n",
    "print(tr2)\n",
    "tr2.show()\n",
    "print(tr2.take(2))\n",
    "tr2.write.json('TerritoryRegion.json')\n",
    "spark.sql('create table TerritoryRegion as ' + sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h4VnZ0MKgUvs"
   },
   "source": [
    "## If you have data that is already collected into a complex datatype and want to flatten it, you could use HQL EXPLODE function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "paYQteGWgUvt"
   },
   "source": [
    "## You could use the Spark explode method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2rSesh3PgUvu"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "tr1.select('RegionID', explode('TerritoryList')).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lXxOSvqAgUvx"
   },
   "source": [
    "## Or if the DataFrame is turned into a Temp View, you could use the HQL query to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fnianeudgUvy"
   },
   "outputs": [],
   "source": [
    "tr1.createOrReplaceTempView('RegionTerritories')\n",
    "sql = \"\"\"\n",
    "SELECT RegionID, TerritoryName\n",
    "FROM RegionTerritories\n",
    "LATERAL VIEW EXPLODE(TerritoryList) EXPLODED_TABLE AS TerritoryName\n",
    "ORDER BY RegionID, TerritoryName\n",
    "\"\"\"\n",
    "spark.sql(sql).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M4XqNW4xgUv2"
   },
   "source": [
    "## Or you could select specific elements from a collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nYvKH3VxgUv3"
   },
   "outputs": [],
   "source": [
    "tr2.createOrReplaceTempView('RegionTerritories')\n",
    "spark.sql(\"select RegionId, RegionName, TerritoryList[0] as First, TerritoryList[size(TerritoryList) - 1] as Last, size(TerritoryList) as TerritoryCount from RegionTerritories\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OgXXtetSgUv6"
   },
   "source": [
    "## If the array is of structs, note the syntax of fetching the elements from the struct uses the . like an object property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t4iyj0JAgUv7"
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT RegionID, RegionName, Territory.TerritoryID AS TerritoryID\n",
    ", Territory.TerritoryName AS TerritoryName\n",
    "FROM RegionTerritories\n",
    "LATERAL VIEW EXPLODE(TerritoryList) EXPLODED_TABLE AS Territory\n",
    "\"\"\"\n",
    "spark.sql(sql).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MDIPBzWWgUwA"
   },
   "source": [
    "## HOMEWORK: ## \n",
    "**First Challenge**\n",
    "\n",
    "Create a Python function to determine if a number is odd or even and use that to select only the even numbered shippers from the TSV folder of northwind. Note the TSV file does not have headers so you will need to do something to make the DataFrame have a meaningful structure. I would suggest using Spark SQL as much as possible to rename and cast the columns which are ShipperID, CompanyName, and Phone.\n",
    "\n",
    "**Second Challenge**\n",
    "\n",
    "Take the Order_LineItems.json folder, read it into a DataFrame, and flatten it and then calculate the average price paid for a product.\n",
    "\n",
    "<br>\n",
    "<details><summary>Click for <b>hint</b></summary>\n",
    "<p>\n",
    "Take a look at the MakeOrders_LineItems.py file provided to see how the Order_LineItems.json was generated in the first place\n",
    "<br>\n",
    "Use modulus with remainder of zero to determine if something is even\n",
    "<br>\n",
    "Use udf to make a version of the function that is callable using dot syntax and udf.register to make a version callable from within a SQL string\n",
    "<br>\n",
    "Use LATERAL VIEW EXPLODE() EXPLODED_TABLE to flatten out the nested format file\n",
    "<br>\n",
    "Once flattened do a traditional aggregate to calculate the average\n",
    "<br>\n",
    "<br>\n",
    "</p>\n",
    "</details>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Day3-SparkSQL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
